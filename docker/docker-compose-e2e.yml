version: "2.4"
services:
  kafka:
    image: wurstmeister/kafka:0.10.0.1-2
    networks:
      - streaming-data-internal
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_HOST_NAME=kafka
      - KAFKA_ADVERTISED_PORT=9092
    depends_on:
      - zookeeper
    mem_limit: 700m  #700mb

  hadoop:
    image: sequenceiq/hadoop-docker:2.7.0
    command: "/etc/bootstrap.sh -d"
    networks:
      - streaming-data-internal
    ports:
      - "50070:50070"
      - "50075:50075"
      - "8088:8088"
      - "8042:8042"
      - "9000:9000"
      - "50010:50010"
    #cpu_shares: 73   #max1024
    #cpu_quota: 50000 #50%
    mem_limit: 700m  #700mb
    mem_reservation: 512m

  hadoop-seed:
    build:
      context: ../hdfs
    networks:
      - streaming-data-internal
    depends_on:
      - hadoop
    restart: on-failure

  zookeeper:
    image: zookeeper:3.3.6
    networks:
      - streaming-data-internal
    ports:
      - "2181:2181"
    mem_limit: 700m  #700mb

  zookeeper-seed:
    build:
      context: ../zookeeper
    networks:
      - streaming-data-internal
    depends_on:
      - zookeeper

  station-sfo-test-producer:
    build:
      context: ../CitibikeApiProducer
      dockerfile: Dockerfile-station-sfo-test
    depends_on:
      - kafka
      - zookeeper-seed
      - webserver
      - mock-server
    networks:
      - streaming-data-internal
    mem_limit: 700m  #700mb

  station-consumer:
    build:
      context: ../StationConsumer
    depends_on:
      - zookeeper-seed
      - kafka
      - station-sfo-test-producer
    volumes:
      - ~/.ivy2:/root/.ivy2:rw
    command: ["./wait-for.sh", "zookeeper:2181", "-t", "30"]
    networks:
      - streaming-data-internal
    restart: on-failure
    mem_limit: 700m  #700mb


  mock-server:
    container_name: "mock-server"
    build:
      context: ../docker/mock_server/
    restart: always
    ports:
      - "5000:5000"
    networks:
      - streaming-data-internal

  webserver:
    container_name: "webserver"
    build:
      context: ../docker/airflow/
    restart: always
    environment:
      - EXECUTOR=Sequential
      - AIRFLOW__CORE__FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=
      - FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=
    volumes:
        - ${PWD}/airflow/dags:/usr/local/airflow/dags
        - ${PWD}/airflow/plugins:/usr/local/airflow/plugins
    depends_on:
      - hadoop
      - mock-server
    ports:
      - "8090:8080"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - streaming-data-internal
    mem_limit: 700m  #700mb
    env_file:
      - config.env

networks:
  streaming-data-internal:
