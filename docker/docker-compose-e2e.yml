version: "3"
services:
  kafka:
    image: wurstmeister/kafka:0.10.0.1-2
    networks:
      - streaming-data-internal
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_HOST_NAME=kafka
      - KAFKA_ADVERTISED_PORT=9092
    depends_on:
      - zookeeper

  hadoop:
    image: sequenceiq/hadoop-docker:2.7.0
    command: "/etc/bootstrap.sh -d"
    networks:
      - streaming-data-internal
    ports:
      - "50070:50070"
      - "50075:50075"
      - "8088:8088"
      - "8042:8042"
      - "9000:9000"
      - "50010:50010"

  hadoop-seed:
    build:
      context: ../hdfs
    networks:
      - streaming-data-internal
    depends_on:
      - hadoop
    restart: on-failure

  zookeeper:
    image: zookeeper:3.3.6
    networks:
      - streaming-data-internal
    ports:
      - "2181:2181"

  zookeeper-seed:
    build:
      context: ../zookeeper
    networks:
      - streaming-data-internal
    depends_on:
      - zookeeper


  station-san-francisco-producer:
    build:
      context: ../CitibikeApiProducer
      dockerfile: Dockerfile-station-san-francisco-e2e
    depends_on:
      - kafka
      - zookeeper-seed
    networks:
      - streaming-data-internal

  raw-station-data-san-francisco-saver:
    build:
      context: ../RawDataSaver
      dockerfile: Dockerfile-station-data-SF
    depends_on:
      - kafka
      - station-san-francisco-producer
      - hadoop-seed
      - zookeeper-seed
    volumes:
      - ~/.ivy2:/root/.ivy2:rw
    networks:
      - streaming-data-internal
    restart: on-failure

  station-consumer:
    build:
      context: ../StationConsumer
    depends_on:
      - zookeeper-seed
      - kafka
      - station-san-francisco-producer
    volumes:
      - ~/.ivy2:/root/.ivy2:rw
    command: ["./wait-for.sh", "zookeeper:2181", "-t", "30"]
    networks:
      - streaming-data-internal
    restart: on-failure

  postgres:
    container_name: "postgres"
    image: postgres:9.6
    volumes:
      - ${PWD}/postgres_mount/postgres:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    env_file: config.env

  webserver:
    container_name: "webserver"
    image: puckel/docker-airflow:1.10.4
    restart: always
    depends_on:
      - postgres
    environment:
      - EXECUTOR=Local
      - AIRFLOW__CORE__FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=
      - FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=

    command: "webserver"

    volumes:
      - ${PWD}/airflow/dags:/usr/local/airflow/dags
    ports:
      - "8090:8080"
      - "588:587"
      - "5000:5000"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    env_file:
      - config.env


  scheduler:
    container_name: "scheduler"
    image: puckel/docker-airflow:1.10.4
    restart: always
    depends_on:
      - webserver
    ports:
      - "587:587"

    environment:
      - EXECUTOR=Local
      - AIRFLOW__CORE__FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=
      - FERNET_KEY=1uU2E6EgdCmdHKebTZjQYvhCzqv8Q597vULxXJy-blE=

    volumes:
      - ${PWD}/airflow/dags:/usr/local/airflow/dags

    env_file:
      - config.env

networks:
  streaming-data-internal:
